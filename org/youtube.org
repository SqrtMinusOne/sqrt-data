#+TITLE: YouTube
#+PROPERTY: header-args:python :comments link
#+PROPERTY: PRJ-DIR ..

Aggregating my YouTube history.

* Sources
** MPV
I often use [[https://mpv.io/][MPV]] with [[https://github.com/yt-dlp/yt-dlp][yt-dlp]] to watch stuff from YouTube.

To record that, here is a script that logs my MPV activity. Put that into =~/.config/mpv/scripts=.

#+begin_src lua :tangle (my/org-prj-dir "scripts/mpv-history.lua")
local utils = require 'mp.utils'
local config_folder = '/logs-sync/mpv';
local log = os.getenv('HOME')..config_folder..'/'..os.date('%Y-%m-%d')..'.log';

local path;

mp.register_event('file-loaded', function ()
      local logfile = io.open(log, 'a+');
      path = mp.get_property('path');
      local data = {
         ['kind'] = 'loaded',
         ['time'] = os.date('!%Y-%m-%dT%TZ'),
         ['path'] = path,
         ['filename'] = mp.get_property('filename'),
         ['length'] = mp.get_property('duration'),
      };
      logfile:write(utils.format_json(data)..'\n');
      logfile:close();
end)

mp.observe_property('pause', 'bool', function (name, value)
      if (not path) then
         return;
      end
      local data = {
         ['kind'] = value and 'pause' or 'play',
         ['time'] = os.date('!%Y-%m-%dT%TZ'),
         ['path'] = path,
         ['pos'] = mp.get_property('time-pos'),
      }
      local logfile = io.open(log, 'a+');
      logfile:write(utils.format_json(data)..'\n');
      logfile:close();
end)

mp.register_event('seek', function ()
      if (mp.get_property_bool('pause')) then
         return;
      end
      local data = {
         ['kind'] = 'seek',
         ['time'] = os.date('!%Y-%m-%dT%TZ'),
         ['path'] = path,
         ['pos'] = mp.get_property('time-pos'),
      }
      local logfile = io.open(log, 'a+');
      logfile:write(utils.format_json(data)..'\n');
      logfile:close();
end)

mp.register_event('end-file', function (data)
      local kind;
      if (data['reason'] == 'eof') then
         kind = 'end';
      elseif (data['reason'] == 'quit' or data['reason'] == 'stop') then
         kind = 'stop';
      end;
      local data = {
         ['kind'] = kind,
         ['time'] = os.date('!%Y-%m-%dT%TZ'),
         ['path'] = path,
         ['pos'] = mp.get_property('time-pos'),
      }
      local logfile = io.open(log, 'a+');
      logfile:write(utils.format_json(data)..'\n');
      logfile:close();
end)
#+end_src
** YouTube website history
:PROPERTIES:
:header-args:js: :tangle (my/org-prj-dir "scripts/youtube-history.js") :comments link
:END:

Apparently that's the only way to get YouTube history with watched time per video.

Parsing the date string of the following form:
- Today
- Yesterday
- Tuesday
- Feb 7
- Feb 7, 2020
#+begin_src js
const DAYS = [
  "Monday",
  "Tuesday",
  "Wednesday",
  "Thursday",
  "Friday",
  "Saturday",
  "Sunday",
];

const MONTHS = [
  "Jan",
  "Feb",
  "Mar",
  "Apr",
  "May",
  "Jun",
  "Jul",
  "Aug",
  "Sep",
  "Oct",
  "Nov",
  "Dec",
];

function parseDayString(day) {
  const today = new Date();
  today.setUTCHours(0);
  today.setUTCMinutes(0);
  today.setUTCSeconds(0);
  today.setUTCMilliseconds(0);
  if (day === "Today") {
    return today.toJSON();
  }
  if (day === "Yesterday") {
    today.setUTCDate(today.getUTCDate() - 1);
    return today.toJSON();
  }
  if (DAYS.includes(day)) {
    const now = today.getDay() - 1 + 7;
    const then = DAYS.indexOf(day) + 7;
    today.setUTCDate(today.getUTCDate() - (now - then));
    return today.toJSON();
  }
  if (day.includes(',')) {
    const year = parseInt(day.split(',')[1]);
    today.setUTCFullYear(year)
    day = day.split(',')[0];
  }
  const parts = day.split(' ');
  today.setUTCMonth(MONTHS.indexOf(parts[0]))
  today.setUTCDate(parseInt(parts[1]))
  return 0;
}
#+end_src

Asyncronous sleep
#+begin_src js
const sleep = (m) => new Promise((r) => setTimeout(r, m));
#+end_src

Parsing one =<ytd-video-renderer>=
#+begin_src js
async function parseVideo(video) {
  if (!video.querySelector('#progress')) {
    await sleep(1000);
    return parseVideo(video);
  }
  const progress = parseInt(video.querySelector("#progress").style.width);
  const link = video.querySelector("#thumbnail").href;
  const id = new URL(link).searchParams.get("v");
  const channel = video.querySelector('[aria-label="Go to channel"]').href;
  return { progress, id, channel };
}
#+end_src

Parsing one =<ytd-video-section-renderer>=
#+begin_src js
async function parseDaySection(section) {
  const date = section.querySelector("#title").textContent;
  const videos = Array.from(section.querySelectorAll("ytd-video-renderer"));
  const result = [];
  for (const video of videos) {
    const datum = await parseVideo(video);
    result.push({ ...datum, date: parseDayString(date) })
  }
  return result;
}
#+end_src

Parsing everything.
#+begin_src js
async function parseAll() {
  const root = document
    .querySelector("ytd-section-list-renderer")
    .querySelector("#contents");
  const res = [];
  let wait = 0;
  let index = 0;
  while (true) {
    const children = Array.from(root.childNodes)
      .filter((n) => n.tagName !== "YTD-CONTINUATION-ITEM-RENDERER")
      .slice(index);
    if (children.length === 0) {
      window.scrollTo(0, 1000000000);
      await sleep(1000);
      if (wait < 20) {
        wait++;
        continue;
      } else {
        break;
      }
    } else {
      wait = 0;
    }
    const child = children[0];
    child.scrollIntoView();
    res.push(...(await parseDaySection(child)));
    index++;
  }
  return res;
}
#+end_src

To run:
#+begin_src js :tangle no
const res = await parseAll()
#+end_src

And save "res".
* Data model
The data model is something like this:
- One channel has multiple videos
- One video has multiple views of different kinds
- One video belongs to one category

The =__init__.py= file:
#+begin_src python :tangle (my/org-prj-dir "sqrt_data/models/youtube/__init__.py")
from .channel import *
from .video import *
from .watch import *
from .category import *
#+end_src

And models:
** Category
#+begin_src python :tangle (my/org-prj-dir "sqrt_data/models/youtube/category.py")
import sqlalchemy as sa
from sqrt_data.models import Base

__all__ = ['Category']


class Category(Base):
    __table_args__ = {'schema': 'youtube'}
    __tablename__ = 'category'

    id = sa.Column(sa.Integer(), primary_key=True)
    name = sa.Column(sa.Text(), nullable=False)
#+end_src
** Channel
#+begin_src python :tangle (my/org-prj-dir "sqrt_data/models/youtube/channel.py")
import sqlalchemy as sa
from sqrt_data.models import Base

__all__ = ['Channel']


class Channel(Base):
    __table_args__ = {'schema': 'youtube'}
    __tablename__ = 'channel'

    id = sa.Column(
        sa.String(256),
        primary_key=True,
    )
    name = sa.Column(sa.Text(), nullable=False)
    url = sa.Column(sa.Text(), nullable=False)
    description = sa.Column(sa.Text(), nullable=True)
    country = sa.Column(sa.String(128), nullable=True)
#+end_src
** Video
#+begin_src python :tangle (my/org-prj-dir "sqrt_data/models/youtube/video.py")
import sqlalchemy as sa
from sqrt_data.models import Base

__all__ = ['Video']


class Video(Base):
    __table_args__ = {'schema': 'youtube'}
    __tablename__ = 'video'

    id = sa.Column(
        sa.String(256),
        primary_key=True,
    )
    channel_id = sa.Column(
        sa.String(256), sa.ForeignKey('youtube.channel.id'), nullable=False
    )
    category_id = sa.Column(
        sa.Integer(), sa.ForeignKey('youtube.category.id'), nullable=False
    )
    name = sa.Column(sa.Text(), nullable=False)
    url = sa.Column(sa.Text(), nullable=False)
    language = sa.Column(sa.String(256), nullable=False)
    duration = sa.Column(sa.Integer(), nullable=False)
    created = sa.Column(sa.Date(), nullable=False)
#+end_src
** Watch
#+begin_src python :tangle (my/org-prj-dir "sqrt_data/models/youtube/watch.py")
import sqlalchemy as sa
from sqrt_data.models import Base

__all__ = ['Watch']


class Watch(Base):
    __table_args__ = {'schema': 'youtube'}
    __tablename__ = 'watch'

    video_id = sa.Column(
        sa.String(256),
        sa.ForeignKey('youtube.video.id'),
        primary_key=True,
    )
    date = sa.Column(sa.Date(), nullable=False, primary_key=True)
    kind = sa.Column(sa.String(256), nullable=False, primary_key=True)
    duration = sa.Column(sa.Integer(), nullable=False)
#+end_src

* Parsing
#+begin_src python :tangle (my/org-prj-dir "sqrt_data/parse/youtube/__init__.py")
from .api import *
from .mpv import *
#+end_src

** Youtube API
:PROPERTIES:
:header-args:python: :tangle (my/org-prj-dir "sqrt_data/parse/youtube/api.py")
:END:

Functions that work with YouTube API.

The required imports:
#+begin_src python
import json
import re
import requests

from sqrt_data.api import settings, DBConn
from sqrt_data.models import Base
from sqrt_data.models.youtube import Channel, Video, Category
#+end_src

Exported functions:
#+begin_src python
__all__ = ['get_video_by_id', 'init_db']
#+end_src

A function to get channel by its id, mostly to make sure that the channel exists.

References:
- [[https://developers.google.com/youtube/v3/docs/channels/list][YouTube Data API docs]]

#+begin_src python
def get_channel_by_id(id, db):
    channel = db.query(Channel).filter_by(id=id).first()
    if channel:
        return channel, False

    channel_response = requests.get(
        'https://youtube.googleapis.com/youtube/v3/channels',
        params={
            'part': 'snippet',
            'id': id,
            'key': settings['google']['api_key']
        }
    )
    channel_response.raise_for_status()
    channel_data = channel_response.json()
    channel_item = {
        'id': id,
        'url': f'https://youtube.com/c/{id}',
        'name': 'unknown'
    }
    if len(channel_data['items']) > 0:
        channel_item['name'] = channel_data['items'][0]['snippet']['title']
        channel_item['description'] = channel_data['items'][0]['snippet'][
            'description']
        channel_item['country'] = channel_data['items'][0]['snippet'].get('country', None)
    channel = Channel(**channel_item)
    db.add(channel)
    return channel, True
#+end_src

Parse video duration.

References:
- [[https://stackoverflow.com/a/49976787][StackOverflow answer]]

#+begin_src python
def yt_time(duration="P1W2DT6H21M32S"):
    """
    Converts YouTube duration (ISO 8061)
    into Seconds

    see http://en.wikipedia.org/wiki/ISO_8601#Durations
    """
    ISO_8601 = re.compile(
        'P'   # designates a period
        '(?:(?P<years>\d+)Y)?'   # years
        '(?:(?P<months>\d+)M)?'  # months
        '(?:(?P<weeks>\d+)W)?'   # weeks
        '(?:(?P<days>\d+)D)?'    # days
        '(?:T' # time part must begin with a T
        '(?:(?P<hours>\d+)H)?'   # hours
        '(?:(?P<minutes>\d+)M)?' # minutes
        '(?:(?P<seconds>\d+)S)?' # seconds
        ')?')   # end of time part
    # Convert regex matches into a short list of time units
    units = list(ISO_8601.match(duration).groups()[-3:])
    # Put list in ascending order & remove 'None' types
    units = list(reversed([int(x) if x != None else 0 for x in units]))
    # Do the maths
    return sum([x*60**units.index(x) for x in units])
#+end_src

Get video by its id.

References:
- [[https://developers.google.com/youtube/v3/docs/videos/list][YouTube Data API docs]]

#+begin_src python
def process_language(item):
    lang = item.get('defaultLanguage', None) or item.get('defaultAudioLanguage', None)
    if not lang:
        return '??'
    return lang.split('-')[0]

def get_video_by_id(id, db):
    video = db.query(Video).filter_by(id=id).first()
    if video:
        return video, False

    video_response = requests.get(
        'https://youtube.googleapis.com/youtube/v3/videos',
        params={
            'part': 'snippet,contentDetails',
            'id': id,
            'key': settings['google']['api_key']
        }
    )
    video_response.raise_for_status()
    video_data = video_response.json()
    if len(video_data['items']) == 0:
        print(f'Video not found : {id}')
        return None, None
    item = video_data['items'][0]['snippet']
    _, new_channel = get_channel_by_id(item['channelId'], db)
    if new_channel:
        db.flush()
    video = Video(**{
        'id': id,
        'channel_id': item['channelId'],
        'category_id': item['categoryId'],
        'name': item['title'],
        'url': f'https://youtube.com/watch?v={id}',
        'language': process_language(item),
        'created': item['publishedAt'],
        'duration': yt_time(video_data['items'][0]['contentDetails']['duration'])
    })
    db.add(video)
    return video, True
#+end_src

Fill the list of categories.

References:
- [[https://developers.google.com/youtube/v3/docs/videoCategories/list][YouTube Data API docs]]

#+begin_src python
def init_categories(db):
    categories_response = requests.get(
        'https://youtube.googleapis.com/youtube/v3/videoCategories',
        params={
            'part': 'snippet',
            'regionCode': 'US',
            'key': settings['google']['api_key']
        }
    )
    categories_response.raise_for_status()
    categories = categories_response.json()['items']
    for category in categories:
        db.merge(
            Category(id=int(category['id']), name=category['snippet']['title'])
        )
#+end_src

Initialize the database.
#+begin_src python
def init_db():
    DBConn()
    DBConn.create_schema('youtube', Base)

    with DBConn.get_session() as db:
        init_categories(db)
        # get_video_by_id('_OsIW3ufZ6I', db)
        db.commit()
#+end_src

** MPV
:PROPERTIES:
:header-args:python: :tangle (my/org-prj-dir "sqrt_data/parse/youtube/mpv.py")
:END:
The most straightforward part.

#+begin_src python
import glob
import json
import re
import pandas as pd
import sqlalchemy as sa
from dateutil import parser
from urllib.parse import urlparse, parse_qs

from sqrt_data.models.youtube import Watch
from sqrt_data.api import HashDict, DBConn, settings

from .api import get_video_by_id
#+end_src

#+begin_src python
__all__ = ['parse_mpv']
#+end_src

Get video id from a query string.
#+begin_src python
def get_video_id(url):
    data = urlparse(url)
    query = parse_qs(data.query)
    id = query.get('v', [None])[0]
    if id is None:
        return
    if id.endswith(']'):
        id = id[:-1]
    return id
#+end_src

Parse one log file, generated by the mpv script.
#+begin_src python
def process_log(filename):
    with open(filename, 'r') as f:
        contents = f.read()

    events = [c for c in contents.split('\n') if len(c) > 0]
    res = []
    current_video = None
    prev_event = None
    acc_duration = 0
    for datum in events:
        try:
            event = json.loads(datum)
        except:
            print(f'Cannot parse: {datum}')
            continue

        if 'kind' not in event or 'time' not in event:
            continue

        time = parser.parse(event['time'])

        if event['kind'] == 'loaded' and 'youtube.com' in event['path']:
            current_video = get_video_id(event['path'])
            if current_video:
                acc_duration, prev_event = 0, event

        if current_video is None:
            continue

        if event['kind'] == 'stop' or event['kind'] == 'end':
            if prev_event['kind'] != 'pause':
                prev_time = parser.parse(prev_event['time'])
                acc_duration += (time - prev_time).total_seconds()
            res.append(
                {
                    'video_id': current_video,
                    'date': time.date().isoformat(),
                    'kind': 'mpv',
                    'duration': acc_duration
                }
            )
            current_video, prev_event, acc_duration = None, None, 0

        if event['kind'] in ['seek', 'pause', 'play']:
            if prev_event['kind'] != 'pause':
                prev_time = parser.parse(prev_event['time'])
                acc_duration += (time - prev_time).total_seconds()
            if event['kind'] != 'pause':
                prev_event = event

    if current_video:
        print(f'Error in {filename}')

    return res, current_video is None
#+end_src

Store results from one log file to database.
#+begin_src python
def store_logs(logs, db):
    date = logs[0]['date']
    df = pd.DataFrame(logs)
    df = df.groupby(by=['video_id', 'kind', 'date']).sum().reset_index()
    db.execute(sa.delete(Watch).where(Watch.date == date))
    missed = False
    for _, item in df.iterrows():
        video, added = get_video_by_id(item['video_id'], db)
        if added:
            db.flush()
        if video:
            db.add(Watch(**item))
        else:
            missed = True
    return missed
#+end_src

#+begin_src python
def parse_mpv(confirm_missed):
    files = glob.glob(f'{settings["youtube"]["mpv_folder"]}/*.log')
    DBConn()
    with DBConn.get_session() as db:
        with HashDict() as h:
            for f in files:
                if h.is_updated(f):
                    logs, is_ok = process_log(f)
                    if is_ok and len(logs) > 0:
                        print(f)
                        missed = store_logs(logs, db)
                        if not missed or confirm_missed:
                            h.save_hash(f)
                db.commit()
                h.commit()
#+end_src
* CLI
:PROPERTIES:
:header-args:python: :tangle (my/org-prj-dir "sqrt_data/cli/youtube.py") :comments link
:END:
The CLI interface via click.

#+begin_src python
import click
from sqrt_data.parse import youtube as youtube_
#+end_src

Export a click group named "youtube"
#+begin_src python
__all__ = ['youtube']

@click.group(help='YouTube stats')
def youtube():
    pass
#+end_src

Initialize the DB
#+begin_src python
@youtube.command(help='Initialize the DB')
def init_db():
    youtube_.init_db()
#+end_src

Parse MPV
#+begin_src python
@youtube.command(help='Parse MPV logs')
@click.option('-c', '--confirm-missing', is_flag=True)
def parse_mpv(confirm_missing):
    youtube_.parse_mpv(confirm_missing)
#+end_src
