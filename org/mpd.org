#+TITLE: MPD data
#+PROPERTY: header-args :mkdirp yes
#+PROPERTY: header-args:python :comments link
#+PROPERTY: PRJ-DIR ..

Collecting and parsing data from [[https://www.musicpd.org/][Music Player Daemon]].

Actually, this includes data from the now defunct Google Play Music. The code for parsing that is somewhere in the history of this repo.

* Agent
Usage:
- Run this to start the logging daemon: =python -m sqrt_data_agent.mpd=
- Run this to dump the library: =python -m sqrt_data_agent.mpd_save_library=

** Logging
:PROPERTIES:
:header-args:python+: :tangle (my/org-prj-dir "sqrt_data_agent/mpd.py")
:END:
MPD doesn't collect log too much, so I have a small daemon doing that.


#+begin_src python
import csv
import logging
import os
import socket
import sys
import time
from datetime import datetime, timedelta

from mpd import MPDClient

from sqrt_data_agent.api import settings
#+end_src

Using [[https://stackoverflow.com/a/7758075][this StackOverflow answer]] to prevent the daemon from being launched multiple times. Works only on Linux.

#+begin_src python
def get_lock(process_name):
    get_lock._lock_socket = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)
    try:
        get_lock._lock_socket.bind('\0' + process_name)
        logging.info('Got the lock')
    except socket.error:
        logging.info('Lock already exists, exiting')
        sys.exit()
#+end_src

Get the filename of the current day log.
#+begin_src python
def get_log_filename():
    return os.path.join(
        settings.mpd.log_folder,
        f'{datetime.now().strftime("%Y-%m-%d")}-{socket.gethostname()}-log.csv'
    )
#+end_src

The script uses [[https://github.com/Mic92/python-mpd2][python-mpd2]], which has a decent documentation. The function below records the current song.

If the fraction of the listened time is greater than =listened_threshold=, the song is considered "listened". This seems to work well for the value of 0.5.
#+begin_src python
def write_song(song):
    time_listened = (datetime.now() - song['start_time']).seconds
    duration = float(song['duration'])
    if (time_listened / duration > settings.mpd.listened_threshold):
        evt_type = 'listened'
    else:
        evt_type = 'skipped'

    event = {
        'file': song['file'],
        'artist': song.get('artist', ''),
        'album_artist': song.get('albumartist', ''),
        'title': song.get('title', ''),
        'album': song.get('album'),
        'time': song['start_time'].isoformat(' ', 'seconds'),
        'type': evt_type,
        **{attr: song.get(attr, '')
           for attr in settings.mpd.custom_attrs}
    }

    fieldnames = event.keys()
    log_file = get_log_filename()
    log_exists = os.path.exists(log_file)
    mode = 'a' if log_exists else 'w'
    with open(log_file, mode) as f:
        writer = csv.DictWriter(f, fieldnames)
        if not log_exists:
            writer.writeheader()
            logging.info('Initialized CSV log')
        writer.writerow(event)
        logging.info('Saved an entry')
#+end_src

Get current song.
#+begin_src python
def get_current_song(mpd: MPDClient):
    status = mpd.status()
    song = mpd.currentsong()
    if song and status['state'] != 'stop':
        time_elapsed = float(status['elapsed'])
        song['start_time'] = datetime.now() - timedelta(
            seconds=int(time_elapsed))
        return song
    return None
#+end_src

Watch the current song in an endless loop.
#+begin_src python
current_song = None

def watch(mpd: MPDClient):
    global current_song

    while True:
        song = get_current_song(mpd)

        if not current_song:
            current_song = song
        elif not song or (song and song['file'] != current_song['file']):
            write_song(current_song)
            current_song = song

        mpd.idle('player')
#+end_src

Connect to the client.
#+begin_src python
def connect():
    mpd = MPDClient()
    mpd.connect('localhost', 6600)
    logging.info('Connect successful, running')
    return mpd
#+end_src

The main function.

I don't remember the details already, but I think I had some issues with keeping connections to MPD, so this function tries to reconnect is the connection was lost.

#+begin_src python
def main():
    last_error = datetime.now()
    error_count = 0

    get_lock('sqrt-data-agent-mpd')

    while True:
        try:
            mpd = connect()
            watch(mpd)
        except Exception as exp:
            logging.error(repr(exp))
            logging.error('Waiting %s seconds, error count: %s',
                          settings.mpd.exception_timeout, error_count)
            time.sleep(settings.mpd.exception_timeout)

            if (datetime.now() - last_error).seconds > 60:
                error_count = 0
            last_error = datetime.now()
            error_count += 1
            if error_count > settings.mpd.exception_count:
                raise exp

if __name__ == "__main__":
    main()
#+end_src
** Storing the library
:PROPERTIES:
:header-args:python: :tangle (my/org-prj-dir "sqrt_data_agent/mpd_save_library.py") :comments link
:END:

Another thing required is to save the current MPD library.

Imports are as follows:
#+begin_src python
import os
import dateutil
import pandas as pd
import numpy as np

from mpd import MPDClient
from sqrt_data_agent.api import settings
#+end_src

Extract the year from the MPD entry:
#+begin_src python
def get_year(datum):
    try:
        if datum['originaldate']:
            return dateutil.parser.parse(datum['originaldate']).year
    except TypeError:
        pass
    if datum['date']:
        try:
            return dateutil.parser.parse(datum['date']).year
        except TypeError:
            pass
    return None
#+end_src

And save the library to the csv file:
#+begin_src python
def save_library():
    mpd = MPDClient()
    mpd.connect("localhost", 6600)

    data = mpd.listallinfo()
    data = [datum for datum in data if 'directory' not in datum]
    df = pd.DataFrame(data)

    df['year'] = df.apply(get_year, axis=1)
    df.duration = df.time
    df['album_artist'] = df.albumartist

    csv_path = os.path.expanduser(settings['mpd']['library_csv'])

    os.makedirs(os.path.dirname(csv_path), exist_ok=True)
    df.to_csv(csv_path, index=False)

if __name__ == '__main__':
    save_library()
#+end_src

* Models
Using SQLAlchemy models here for some reason.

The model for a particular song:
#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/models/mpd/MpdSong.py")
import sqlalchemy as sa
from sqrt_data_service.models import Base

__all__ = ['MpdSong']

class MpdSong(Base):
    __tablename__ = 'MpdSong'
    __table_args__ = {'schema': 'mpd'}

    id = sa.Column(
        sa.BigInteger(),
        primary_key=True,
        nullable=False,
        unique=True,
        autoincrement=True,
    )

    file = sa.Column(
        sa.Text(),
        nullable=False,
        unique=True
    )

    duration = sa.Column(sa.Integer(), nullable=False)
    artist = sa.Column(sa.Text(), nullable=True)
    album_artist = sa.Column(sa.Text(), nullable=False)
    album = sa.Column(sa.Text(), nullable=False)
    title = sa.Column(sa.Text(), nullable=False)
    year = sa.Column(sa.Integer(), nullable=True)
    musicbrainz_trackid = sa.Column(sa.String(256), nullable=True)
#+end_src

The model that records that a particular song was listened at a particular time.
#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/models/mpd/SongListened.py")
import sqlalchemy as sa
from sqrt_data_service.models import Base

__all__ = ['SongListened']

class SongListened(Base):
    __tablename__ = 'SongListened'
    __table_args__ = {'schema': 'mpd'}

    song_id = sa.Column(
        sa.BigInteger(),
        sa.ForeignKey('mpd.MpdSong.id'),
        primary_key=True,
        nullable=False
    )

    time = sa.Column(
        sa.DateTime(),
        nullable=False,
        primary_key=True
    )
#+end_src

And =__init__.py= for the MPD models package:
#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/models/mpd/__init__.py")
from .MpdSong import *
from .SongListened import *
#+end_src

* Flow
:PROPERTIES:
:header-args:python: :tangle (my/org-prj-dir "sqrt_data_service/flows/mpd/flow.py") :comments link
:END:

#+begin_src python
import os
import sys
import logging
import glob

import pandas as pd
from tqdm import tqdm

import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import insert as pg_insert

from sqrt_data_service.api import settings, DBConn, FileHasher
from sqrt_data_service.models import Base
from sqrt_data_service.models.mpd import MpdSong, SongListened
#+end_src

#+begin_src python
__init__ = ['load_mpd']
#+end_src

** Loading the library
First, load the library:

#+begin_src python
def load_library():
    csv_path = os.path.expanduser(settings['mpd']['library_csv'])
    hasher = FileHasher()

    if not hasher.is_updated(csv_path):
        logging.info('MPD library already saved, skipping')
        return

    logging.info('Saving MPD Library')
    df = pd.read_csv(csv_path)
    DBConn.create_schema('mpd', Base)

    with DBConn.get_session() as db:
        tracks = list(df.itertuples(index=False))

        song_data = []
        for track in tqdm(tracks):
            track = track._asdict()
            song_datum = {k:v for k, v in track.items() if k in MpdSong.__table__.columns.keys()}
            if pd.isna(song_datum['year']):
                song_datum['year'] = None
            song_data.append(song_datum)

        insert_stmt = pg_insert(MpdSong)
        upsert_stmt = insert_stmt.on_conflict_do_update(
            constraint='MpdSong_file_key',
            set_={
                'duration': insert_stmt.excluded.duration,
                'artist': insert_stmt.excluded.artist,
                'album_artist': insert_stmt.excluded.album_artist,
                'album': insert_stmt.excluded.album,
                'title': insert_stmt.excluded.title,
                'year': insert_stmt.excluded.year,
                'musicbrainz_trackid': insert_stmt.excluded.musicbrainz_trackid
            }
        )

        db.execute(upsert_stmt.values(song_data))
        hasher.save_hash(csv_path, db)
        db.commit()

        logging.info(f'Saved {len(song_data)} records')
#+end_src

** Loading the logs
Second, load the logs:

Getting a list of logs to load:
#+begin_src python
def get_logs_to_put():
    folder = os.path.expanduser(settings['mpd']['log_folder'])
    logs = glob.glob(f"{folder}/*.csv")
    hasher = FileHasher()
    with DBConn.get_session() as db:
        return [log for log in logs if hasher.is_updated(log, db)]
#+end_src

Save one log file:
#+begin_src python
def put_log(filename):
    logging.info('Reading %s', filename)
    df = pd.read_csv(filename)
    records = df.to_dict(orient='records')
    all_found = True
    hasher = FileHasher()
    with DBConn.get_session() as db:
        for record in tqdm(records):
            if record['type'] == 'skipped':
                continue
            song = db.execute(
                sa.select(MpdSong).where(MpdSong.file == record['file'])
            ).scalar_one_or_none()
            if song:
                listened = SongListened(song_id=song.id, time=record['time'])
                db.merge(listened)
            else:
                logging.error('Song %s not found', record['file'])
                all_found = False
        if all_found:
            hasher.save_hash(filename, db)
        db.commit()
#+end_src

** Post-processing
Create a view to make things a bit easier for Metabase:
#+begin_src sql :noweb-ref mpd-view
drop view if exists mpd."MpdSongListened";
create view mpd."MpdSongListened" as
select
    S.title title,
    S.album album,
    S.album_artist artist,
    S.duration::float4 / 60 duration,
    S.year "year",
    L.time "time"
from mpd."SongListened" L
left join mpd."MpdSong" S ON L.song_id = S.id
order by time asc;
#+end_src

#+begin_src python :noweb yes
MPD_VIEW = """
<<mpd-view>>
"""

def create_views():
    DBConn.engine.execute(MPD_VIEW)
#+end_src

** Flow

Putting all this together:
#+begin_src python
def load_mpd():
    DBConn()

    load_library()
    logs = get_logs_to_put()
    logging.info(f'Found unprocessed MPD logs: {len(logs)}')
    for log in logs:
        put_log(log)
        logging.info(f'Processed MPD log: {log}')

    create_views()
#+end_src

* CLI
:PROPERTIES:
:header-args:python: :tangle (my/org-prj-dir "sqrt_data_service/flows/mpd/cli.py") :comments link
:END:

Create the deployment:
#+begin_src python
import click

from sqrt_data_service.api import settings

from .flow import load_mpd

__all__ = ['mpd']

@click.group()
def mpd():
    pass

@mpd.command(help='Load MPD', name='load')
def load_mpd_cmd():
    load_mpd()
#+end_src

#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/flows/mpd/__init__.py")
from .flow import *
from .cli import *
#+end_src
