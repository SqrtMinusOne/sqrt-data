#+TITLE: sqrt-data core
#+PROPERTY: header-args :mkdirp yes
#+PROPERTY: header-args:bash   :tangle-mode (identity #o755) :comments link :shebang "#!/usr/bin/env bash"
#+PROPERTY: header-args:python :comments link :eval no
#+PROPERTY: header-args:scheme :comments link :eval no
#+PROPERTY: PRJ-DIR ..

I'd name this "Electric Boogaloo", but the window of opportunity for that is long gone.

* Service API
The central part of the project is a package called =sqrt_data_service=, which does most of the data processing.

Some of the code is duplicated in the agent, because I've decided that extracting the common functionality into a separate package isn't worth it. Org Mode has noweb anyway.

#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/api/__init__.py")
from .config import *
from .db import *
from .hash import *
#+end_src

** Configuration
Let's start with configuration. I like the [[https://www.dynaconf.com/][dynaconf]] library to manage my Python configs.

It's convinient enough but at the same time allows some logic in its syntax, for instance string interpolation.

#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/api/config.py")
import os

from dynaconf import Dynaconf

__all__ = ['settings']

settings_files = [
    # os.path.expanduser('~/.config/sqrt-data/config.toml'),
    'config.service.toml'
]

if all([not os.path.exists(f) for f in settings_files]):
    print('No config found!')

settings = Dynaconf(settings_files=settings_files)
#+end_src

The library allows multiple configuration formats, of which I prefer TOML.

#+begin_src conf-toml :tangle (my/org-prj-dir "config.service.toml")
dynaconf_merge = true

[database]
user = 'postgres'
password = 'localdbpass'
database = 'data'
host = 'localhost'
port = 5432

[general]
root = '@format {env[HOME]}/logs-sync-debug'
temp_data_folder = '/tmp/sqrt-data'
cli_log = '@format {env[HOME]}/.local/share/sqrt-data/cli.log'

[prefect]
queue = 'main'

[waka]
api_key = 'dummy'
api_url = 'https://wakatime.com/api/v1'
schema = 'wakatime'
#+end_src

** Database
*** Connection
I use [[https://www.sqlalchemy.org/][SQLAlchemy]] to work with the database. I have some things that I don't like about the framework, but I worked with it enough to know where to avoid the rough edges. Or so I hope.

Also, the framework isn't the only thing that does schema manipulations (pandas also can do it), so I can't [[https://alembic.sqlalchemy.org/en/latest/autogenerate.html][autogenerate]] migrations.

Here's the class that has been into a lot of my projects.

#+begin_src python :noweb yes :tangle (my/org-prj-dir "sqrt_data_service/api/db.py")
import logging
from contextlib import contextmanager
from sqlalchemy import create_engine
from sqlalchemy.orm import scoped_session, sessionmaker

from .config import settings

__all__ = ['DBConn']


class DBConn:
    engine = None
    Session = None
    Base = None

    <<db-dbconn>>
#+end_src

A "constructor" that just sets up the class variables. Call this somewhere in the project initialization flow.

#+begin_src python :noweb-ref db-dbconn :tangle no
def __init__(self, **kwargs):
    DBConn.engine = DBConn.get_engine(**kwargs)
    DBConn.Session = sessionmaker()
    DBConn.Session.configure(bind=self.engine)
    DBConn.scoped_session = scoped_session(DBConn.Session)
    logging.info('Initialized database connection')
#+end_src

Reset the class. The original project in the galaxy far, far away used this for unit tests.

#+begin_src python :noweb-ref db-dbconn :tangle no
@classmethod
def reset(cls):
    cls.engine = cls.Session = None
#+end_src

Get the database session object.

#+begin_src python :noweb-ref db-dbconn :tangle no
@staticmethod
@contextmanager
def get_session(**kwargs):
    session = DBConn.Session(**kwargs)
    yield session
    session.close()
#+end_src

Usage of the above method is as follows:
#+begin_src python :tangle no
with DBConn.get_session() as db:
    db.<do-stuff>
#+end_src

A similar method that ensures that a session exists.
#+begin_src python :noweb-ref db-dbconn :tangle no
@staticmethod
@contextmanager
def ensure_session(session, **kwargs):
    if session is None:
        session = DBConn.Session(**kwargs)
        yield session
        session.close()
    else:
        yield session
#+end_src

Get a URL and fresh database engine. The engine object can be passed to pandas, by the way.
#+begin_src python :noweb-ref db-dbconn :tangle no
@staticmethod
def get_url(user=None, password=None, **kwargs):
    url = "postgresql://{0}:{1}@{2}:{3}/{4}".format(
        user or settings.database.user, password or
        settings.database.password, settings.database.host,
        settings.database.port, settings.database.database
    )
    return url

@staticmethod
def get_engine(**kwargs):
    url = DBConn.get_url(**kwargs)
    return create_engine(url, **kwargs)
#+end_src

Finally, a method to create tables in a given schema.
#+begin_src python :noweb-ref db-dbconn :tangle no
@staticmethod
def create_schema(schema, Base=None):
    DBConn.engine.execute(f'CREATE SCHEMA IF NOT EXISTS {schema}')
    if Base is not None:
        tables = []
        for name, table in Base.metadata.tables.items():
            if table.schema == schema:
                tables.append(table)
        Base.metadata.create_all(DBConn.engine, tables)
#+end_src

*** Models
Base model for SQLAlchemy:

#+begin_src python :noweb yes :tangle (my/org-prj-dir "sqrt_data_service/models/base.py")
from sqlalchemy.ext.declarative import declarative_base

__all__ = ['Base']

Base = declarative_base()
#+end_src

#+begin_src python :noweb yes :tangle (my/org-prj-dir "sqrt_data_service/models/__init__.py")
from .base import *
from .hash import *
#+end_src

*** Migrations
I use [[https://alembic.sqlalchemy.org/en/latest/][alembic]] for occasional database migrations.

As I said above, I can't use the autogenerate feature, so some manual management is required.

=alembic.ini= is created automatically by =alembic init=, but why not add it here for completeness' sake.

#+begin_src conf-space  :tangle (my/org-prj-dir "alembic.ini")
[alembic]
script_location = migrations
prepend_sys_path = .
version_path_separator = os

# This is overriden in env.py
sqlalchemy.url = driver://user:pass@localhost/dbname

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
#+end_src

=migrations/env.py= is another part of the config. Some imports:

#+begin_src python :tangle (my/org-prj-dir "migrations/env.py")
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context
#+end_src

Set the database URL from the config:

#+begin_src python :tangle (my/org-prj-dir "migrations/env.py")
config = context.config

from sqrt_data_service.api import DBConn

config.set_section_option(
    config.config_ini_section, 'sqlalchemy.url', DBConn.get_url()
)
#+end_src

Interpret the config file for Python logging.
#+begin_src python :tangle (my/org-prj-dir "migrations/env.py")
if config.config_file_name is not None:
    fileConfig(config.config_file_name)
#+end_src

Set the metadata object:
#+begin_src python :tangle (my/org-prj-dir "migrations/env.py")
from sqrt_data_service import models

target_metadata = models.Base.metadata
#+end_src

And the rest is copied from the version of the file generated by =alembic init=:

#+begin_src python :tangle (my/org-prj-dir "migrations/env.py")
def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
#+end_src

** Hashes
Because the data is synced via files, I need to track changes in these files. The easiest way is to store hashes of the files.

I used to use [[https://github.com/RaRe-Technologies/sqlitedict][SqliteDict]] for that purpose, but at some point realized that it's easier to store them in the database.

With that said, here's the model definition

#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/models/hash.py")
import sqlalchemy as sa
from sqrt_data_service.models import Base

__all__ = ['FileHash']


class FileHash(Base):
    __table_args__ = {'schema': 'hashes'}
    __tablename__ = 'file_hash'

    file_name = sa.Column(
        sa.String(1024),
        primary_key=True,
    )
    hash = sa.Column(sa.String(256), nullable=False)
#+end_src

And the corresponding logic:
#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/api/hash.py")
import logging
import os
import subprocess
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import insert as pg_insert

from .config import settings
from sqrt_data_service.api import DBConn
from sqrt_data_service.models import FileHash
#+end_src

First, calculate the hashsum:
#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/api/hash.py")
def md5sum(filename):
    res = subprocess.run(
        ['md5sum', filename],
        capture_output=True,
        check=True,
        cwd=settings.general.root
    ).stdout
    res = res.decode('utf-8')
    return res.split(' ')[0]
#+end_src

And the wrapper class:
#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/api/hash.py")
class FileHasher:
    def __init__(self):
        DBConn()

    def is_updated(self, file_name, db=None):
        with DBConn.ensure_session(db) as db:
            saved = db.execute(
                sa.select(FileHash).where(FileHash.file_name == file_name)
            ).scalar_one_or_none()
            if saved is None:
                return True
            return saved.hash != md5sum(file_name)

    def save_hash(self, file_name, db=None):
        hash = md5sum(file_name)
        was_ensured = db is None
        with DBConn.ensure_session(db) as db:
            insert_stmt = pg_insert(FileHash)
            upsert_stmt = insert_stmt.on_conflict_do_update(
                constraint='file_hash_pkey',
                set_={'hash': insert_stmt.excluded.hash}
            )
            db.execute(upsert_stmt, { 'file_name': file_name, 'hash': hash })
            if was_ensured:
                db.commit()
#+end_src

** CLI entrypoint
:PROPERTIES:
:header-args:python+: :tangle (my/org-prj-dir "sqrt_data_service/manage.py")
:END:
There used to me more stuff in the CLI before I migrated to [[https://www.prefect.io/][prefect.io]], but some things still remain. My CLI library of choice is [[https://click.palletsprojects.com/en/8.0.x/][click]].

#+begin_src python
import click
import os

from sqrt_data_service.api import FileHasher, DBConn
from sqrt_data_service.models import Base

@click.group()
def cli():
    print(f'CWD: {os.getcwd()}')
#+end_src

A few commands to work with hashes:
#+begin_src python
@click.group(help='Hashes')
def hash():
    pass

@hash.command()
@click.option('-f', '--file-name', required=True, type=str)
def check_hash(file_name):
    hasher = FileHasher()
    if not os.path.exists(file_name):
        print('File not found')
    else:
        result = hasher.is_updated(file_name)
        print(f'Updated: {result}')


@hash.command()
@click.option('-f', '--file-name', required=True, type=str)
def save_hash(file_name):
    hasher = FileHasher()
    hasher.save_hash(file_name)

cli.add_command(hash)
#+end_src

Create schema:
#+begin_src python
@click.group(help='Database')
def db():
    pass

@db.command()
@click.option('-n', '--name', required=True, type=str)
def create_schema(name):
    DBConn()
    DBConn.create_schema(name, Base)

cli.add_command(db)
#+end_src

To make this work, we need to invoke =cli()=. Now the CLI can be used with =python -m sqrt_data_service.manage=:

#+begin_src python
if __name__ == '__main__':
    cli()
#+end_src

And the following =__main__.py= to allow running the CLI with =python -m sqrt_data_service=:

#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/__main__.py")
from .manage import cli

if __name__ == '__main__':
    cli()
#+end_src

* Deploy
