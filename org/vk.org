#+TITLE: VK data
#+PROPERTY: header-args :mkdirp yes
#+PROPERTY: header-args:python :comments link
#+PROPERTY: PRJ-DIR ..

[[https://vk.com][Vk.com]] is rather totalitarian in terms of (not) giving the user a voice on what to do with their data, but even they are forced by GDPR to [[https://vk.com/data_protection?lang=en&section=rules][provide a copy of what they have on you]].

Also, I don't use the platform for anything but messaging, so I won't parse anything else.

Edit <2022-11-28>: I've left the platform, but I keep this file to merge data with other messengers.

* Flow
:PROPERTIES:
:header-args:python: :tangle (my/org-prj-dir "sqrt_data_service/flows/vk/flow.py") :comments link
:END:

The dump itself is a set of HTML files, which is a bit awkward to parse.

So, the imports:
#+begin_src python
import argparse
import pandas as pd
import os
import sys
import sqlalchemy as sa

from sqrt_data_service.api import DBConn, settings

from bs4 import BeautifulSoup
from collections import deque
from dateutil import parser
from tqdm import tqdm
#+end_src

#+begin_src python
__all__ = ['vk_load']
#+end_src

I don't understand why some dumps have labels in English and some in Russian. The only important difference between the versions is in the date format anyway.

So here is the English version:
#+begin_src python
def parse_date_english(date):
    is_edited = False
    if date.endswith(' (edited)'):
        is_edited = True
        date = date[:-9]
    date = date[2:]
    date = parser.parse(date)
    return is_edited, date
#+end_src

And the Russian one:
#+begin_src python
MONTHS = [
    'янв', 'фев', 'мар', 'апр', 'мая', 'июн', 'июл', 'авг', 'сен', 'окт', 'ноя',
    'дек'
]


def parse_date_russian(date):
    is_edited = False
    if date.endswith(' (ред.)'):
        is_edited = True
        date = date[:-7]
    day, month, year, _, time = date.split()

    month = MONTHS.index(month) + 1
    date = parser.parse(time).replace(day=int(day), month=month, year=int(year))
    return is_edited, date
#+end_src

The dump is structured as follows: the root folder has the "messages" folder. The latter has one directory per target, and the individual directory has a set of HTML files with messages.

So, the following function parses one HTML file. It returns a DataFrame with the following columns:
- =name= - user/chat name
- =sender=
- =is_outgoing= - whether you are the sender
- =date=
- =message=
- =is_edited=

#+begin_src python
def parse_file(path):
    with open(path, 'r', encoding='windows-1251') as f:
        soup = BeautifulSoup(f, features="html.parser")

    content = soup.html.body.div
    name = content.find(class_='page_content page_block'
                       ).h2.div.find(class_='_header_inner'
                                    ).find('div', class_='ui_crumb').text
    items = content.find(class_='page_content page_block'
                        ).find(class_='wrap_page_content')

    senders, dates, messages, edited = deque(), deque(), deque(), deque()
    is_group = None

    for item in items.find_all(class_='item'):
        header = item.div.find(class_='message__header')
        author, date = header.text.split(', ', 1)

        is_edited, date = parse_date_english(date)
        message_div = item.div.find('div', class_='')
        message = ''
        for content in message_div.contents:
            if content.name is None:
                if message:
                    message += '\n' + content
                else:
                    message += content

        if message:
            senders.append(author)
            dates.append(date)
            messages.append(message)
            edited.append(is_edited)

            if is_group is None and author == name:
                is_group = False

    if is_group is None:
        is_group = True

    global_author = settings['vk']['author']

    df = pd.DataFrame(
        {
            "target": name,
            "sender": [s if s != 'You' else global_author for s in senders],
            "is_outgoing": [s == 'You' for s in senders],
            "message": messages,
            "date": dates,
            "is_edited": edited,
            "is_group": is_group
        }
    )
    return df
#+end_src

Next, parse the directory for a single target:
#+begin_src python
def parse_directory(path):
    logger = get_run_logger()
    files = sorted([f for f in os.listdir(path) if f.endswith('html')])
    df = pd.DataFrame(
        {
            'target': pd.Series(dtype='str'),
            'sender': pd.Series(dtype='str'),
            'is_outgoing': pd.Series(dtype='bool'),
            'message': pd.Series(dtype='str'),
            'date': pd.Series(dtype='datetime64[ns]'),
            'is_edited': pd.Series(dtype='bool'),
            'is_group': pd.Series(dtype='bool')
        }
    )
    for file in files:
        df_ = parse_file(os.path.join(path, file))
        df = pd.concat([df, df_])
    df = df.sort_values(by='date').reset_index(drop=True)
    logger.info(f'Parsed: {path}')
    if len(df) > 0:
        df.is_outgoing = df.is_outgoing.astype(bool)
        df.is_edited = df.is_edited.astype(bool)
    return df
#+end_src

And store that in the database:
#+begin_src python
def store_directory(df):
    DBConn()
    df.to_sql(
        'messages',
        schema=settings["vk"]["schema"],
        con=DBConn.engine,
        if_exists='append'
    )
#+end_src

The flow that calls the task for each element:
#+begin_src python
def vk_load(directory):
    DBConn()
    schema = settings["vk"]["schema"]
    with DBConn.get_session() as db:
        db.execute(sa.text(f'create schema if not exists "{schema}"'))
        exists = db.execute(
            sa.text(
                f"select exists(select from information_schema.tables where table_schema = '{schema}' and table_name = 'messages')"
            )
        ).scalar_one()
        if exists:
            db.execute(sa.text(f'truncate table {schema}.messages'))
        db.commit()

    futures = []

    for f in os.listdir(directory):
        path = os.path.join(directory, f)
        if not os.path.isdir(path) or path.endswith('.ipynb_checkpoints'):
            continue
        df = parse_directory(path)
        store_directory(df)
#+end_src

* CLI
:PROPERTIES:
:header-args:python: :tangle (my/org-prj-dir "sqrt_data_service/flows/vk/cli.py") :comments link
:END:

#+begin_src python
import click

from sqrt_data_service.api import settings

from .flow import vk_load

__all__ = ['vk']

@click.group()
def vk():
    pass

@vk.command(help='Load VK', name='load')
@click.option('--folder', type=click.Path(exists=True))
def load_cmd():
    vk_load(folder)
#+end_src

#+begin_src python :tangle (my/org-prj-dir "sqrt_data_service/flows/vk/__init__.py")
from .flow import *
from .cli import *
#+end_src
